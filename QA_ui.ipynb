{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Set the USER_AGENT environment variable\n",
    "os.environ['USER_AGENT'] = 'DocumentQA/1.0'\n",
    "import gradio as gr\n",
    "from langchain_community.document_loaders import PyPDFLoader, OnlinePDFLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, db_directory=\"persistent_vector_db\"):\n",
    "        # Initialize or load the persistent vector database from disk\n",
    "        self.embeddings = OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True)\n",
    "        self.vector_db = Chroma(persist_directory=db_directory,\n",
    "                                embedding_function=self.embeddings,\n",
    "                                collection_name=\"persistent-rag-chroma\")\n",
    "        self.uploaded_docs = self._load_existing_docs()  # Initialize with existing documents\n",
    "\n",
    "    def _load_existing_docs(self):\n",
    "        # Load existing documents from the vector store if possible\n",
    "        # Here we assume that document names were stored as metadata\n",
    "        uploaded_docs = []\n",
    "        for doc in self.vector_db.get()[\"documents\"]:\n",
    "            if \"metadata\" in doc:\n",
    "                uploaded_docs.append(doc[\"metadata\"].get(\"source\", \"Unknown Document\"))\n",
    "        return uploaded_docs\n",
    "\n",
    "    def load_documents(self, files):\n",
    "        docs_list = []\n",
    "        loaders = {\n",
    "            'pdf': PyPDFLoader,\n",
    "            'txt': self._load_text_file,\n",
    "            'docx': OnlinePDFLoader,  # Assuming you have a specific loader for docx files\n",
    "            # Add more file type loaders here if needed\n",
    "        }\n",
    "\n",
    "        for file in files:\n",
    "            ext = file.name.split('.')[-1].lower()\n",
    "            loader = loaders.get(ext)\n",
    "            if loader:\n",
    "                if ext == 'txt':\n",
    "                    docs = loader(file.name)\n",
    "                else:\n",
    "                    docs = loader(file.name).load()\n",
    "\n",
    "                # Ensure docs are in the expected format\n",
    "                for doc in docs:\n",
    "                    if isinstance(doc, Document):\n",
    "                        docs_list.append(doc)\n",
    "                    else:\n",
    "                        docs_list.append(Document(page_content=doc.get('page_content', doc), metadata=doc.get('metadata', {\"source\": file.name})))\n",
    "\n",
    "                # Track the uploaded document by just the name and extension\n",
    "                file_name = os.path.basename(file.name)  # Get just the file name and extension\n",
    "                self.uploaded_docs.append(file_name)\n",
    "\n",
    "        # Process and add the documents to the vector store\n",
    "        self._process_and_store_documents(docs_list)\n",
    "\n",
    "    def _load_text_file(self, file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        return [Document(page_content=text, metadata={\"source\": file_path})]\n",
    "\n",
    "    def _process_and_store_documents(self, docs_list):\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=7500,\n",
    "            chunk_overlap=100,\n",
    "        )\n",
    "        doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "        # Add documents to the vector store\n",
    "        self.vector_db.add_documents(doc_splits)\n",
    "        # No need to explicitly persist; the vector store should handle it automatically\n",
    "\n",
    "    def get_retriever(self):\n",
    "        return self.vector_db.as_retriever()\n",
    "\n",
    "    def get_uploaded_docs(self):\n",
    "        return \"\\n\".join(self.uploaded_docs)  # Return a formatted string of uploaded documents\n",
    "\n",
    "\n",
    "class QuestionAnsweringSystem:\n",
    "    def __init__(self):\n",
    "        self.processor = DocumentProcessor()\n",
    "        self.model_local = ChatOllama(model=\"mistral\")\n",
    "        self.prompt_template = \"\"\"Answer the question based only on the following context:\n",
    "        {context}\n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "\n",
    "    def load_and_process(self, files):\n",
    "        self.processor.load_documents(files)\n",
    "\n",
    "    def answer_question(self, question):\n",
    "        retriever = self.processor.get_retriever()\n",
    "        after_rag_prompt = ChatPromptTemplate.from_template(self.prompt_template)\n",
    "        after_rag_chain = (\n",
    "            {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "            | after_rag_prompt\n",
    "            | self.model_local\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        return after_rag_chain.invoke(question)\n",
    "\n",
    "    def get_uploaded_docs(self):\n",
    "        return self.processor.get_uploaded_docs()\n",
    "\n",
    "\n",
    "# Gradio Interfaces for Uploading Documents and Asking Questions\n",
    "qa_system = QuestionAnsweringSystem()  # Create a single instance of QuestionAnsweringSystem\n",
    "\n",
    "def upload_documents(files):\n",
    "    qa_system.load_and_process(files)\n",
    "    return \"Documents uploaded and processed successfully!\", qa_system.get_uploaded_docs()\n",
    "\n",
    "def query_documents(question):\n",
    "    return qa_system.answer_question(question)\n",
    "\n",
    "iface = gr.Blocks()\n",
    "\n",
    "with iface:\n",
    "    with gr.Tab(\"Upload Documents\"):\n",
    "        file_input = gr.File(label=\"Upload Documents\", file_count=\"multiple\", file_types=[\"pdf\", \"txt\", \"docx\"])\n",
    "        upload_button = gr.Button(\"Upload\")\n",
    "        upload_output = gr.Textbox(label=\"Upload Status\")\n",
    "        document_list = gr.Textbox(label=\"Uploaded Documents\", interactive=False)\n",
    "        upload_button.click(upload_documents, inputs=file_input, outputs=[upload_output, document_list])\n",
    "    \n",
    "    with gr.Tab(\"Query Documents\"):\n",
    "        question_input = gr.Textbox(label=\"Question\")\n",
    "        query_button = gr.Button(\"Ask\")\n",
    "        query_output = gr.Textbox(label=\"Answer\")\n",
    "        query_button.click(query_documents, inputs=question_input, outputs=query_output)\n",
    "\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
